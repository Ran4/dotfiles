#!/usr/bin/env python3
import sys
import openai
import os
import argparse


# Manually load the OPENAI_API_KEY from the .env file
def load_api_key(dotenv_path):
    with open(dotenv_path, "r") as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#"):  # Ignore comments and empty lines
                key, value = line.split("=", 1)
                if key.strip() == "OPENAI_API_KEY":
                    return value.strip('"').strip("'")
    return None


# Load the API key from the specified .env file
dotenv_path = os.path.expanduser("~/it_total/ttyd/backend-ttyd/.env")
openai.api_key = load_api_key(dotenv_path)


def main():
    parser = argparse.ArgumentParser(description="AI CLI tool", add_help=False)
    parser.add_argument(
        "--model", default="gpt-4.1", help="Model to use (default: gpt-4.1)"
    )

    # Parse known args to separate --model from the query
    args, remaining = parser.parse_known_args()

    query = " ".join(remaining)
    if not query:
        print("Usage: ai [--model MODEL_NAME] <your query>")
        sys.exit(1)

    try:
        response = openai.chat.completions.create(
            model=args.model,
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant who answers concisely.",
                },
                {"role": "user", "content": query},
            ],
            temperature=0,
        )
        answer = response.choices[0].message.content
        assert answer, "Got no answer from llm!"
        print(answer.strip())

    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    main()
